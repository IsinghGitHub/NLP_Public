{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optimize\n",
    "import transform\n",
    "import utils\n",
    "import vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --checkpoint CHECKPOINT --in-path IN_PATH\n",
      "                             --out-path OUT_PATH [--device DEVICE]\n",
      "                             [--batch-size BATCH_SIZE]\n",
      "                             [--allow-different-dimensions]\n",
      "ipykernel_launcher.py: error: the following arguments are required: --checkpoint, --in-path, --out-path\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "# %load evaluate.py\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "sys.path.insert(0, 'E:\\Documents\\Data_Science\\Analytics_vidya\\FaStyle_Transfer\\fast-style-transfer-master\\src')\n",
    "import transform, numpy as np, vgg, pdb, os\n",
    "import scipy.misc\n",
    "import tensorflow as tf\n",
    "from utils import save_img, get_img, exists, list_files\n",
    "from argparse import ArgumentParser\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import json\n",
    "import subprocess\n",
    "import numpy\n",
    "#from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "#import moviepy.video.io.ffmpeg_writer as ffmpeg_writer\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "DEVICE = '/gpu:0'\n",
    "\n",
    "\n",
    "def ffwd_video(path_in, path_out, checkpoint_dir, device_t='/gpu:0', batch_size=4):\n",
    "    video_clip = VideoFileClip(path_in, audio=False)\n",
    "    video_writer = ffmpeg_writer.FFMPEG_VideoWriter(path_out, video_clip.size, video_clip.fps, codec=\"libx264\",\n",
    "                                                    preset=\"medium\", bitrate=\"2000k\",\n",
    "                                                    audiofile=path_in, threads=None,\n",
    "                                                    ffmpeg_params=None)\n",
    "\n",
    "    g = tf.Graph()\n",
    "    soft_config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    soft_config.gpu_options.allow_growth = True\n",
    "    with g.as_default(), g.device(device_t), \\\n",
    "            tf.Session(config=soft_config) as sess:\n",
    "        batch_shape = (batch_size, video_clip.size[1], video_clip.size[0], 3)\n",
    "        img_placeholder = tf.placeholder(tf.float32, shape=batch_shape,\n",
    "                                         name='img_placeholder')\n",
    "\n",
    "        preds = transform.net(img_placeholder)\n",
    "        saver = tf.train.Saver()\n",
    "        if os.path.isdir(checkpoint_dir):\n",
    "            ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "            if ckpt and ckpt.model_checkpoint_path:\n",
    "                saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "            else:\n",
    "                raise Exception(\"No checkpoint found...\")\n",
    "        else:\n",
    "            saver.restore(sess, checkpoint_dir)\n",
    "\n",
    "        X = np.zeros(batch_shape, dtype=np.float32)\n",
    "\n",
    "        def style_and_write(count):\n",
    "            for i in range(count, batch_size):\n",
    "                X[i] = X[count - 1]  # Use last frame to fill X\n",
    "            _preds = sess.run(preds, feed_dict={img_placeholder: X})\n",
    "            for i in range(0, count):\n",
    "                video_writer.write_frame(np.clip(_preds[i], 0, 255).astype(np.uint8))\n",
    "\n",
    "        frame_count = 0  # The frame count that written to X\n",
    "        for frame in video_clip.iter_frames():\n",
    "            X[frame_count] = frame\n",
    "            frame_count += 1\n",
    "            if frame_count == batch_size:\n",
    "                style_and_write(frame_count)\n",
    "                frame_count = 0\n",
    "\n",
    "        if frame_count != 0:\n",
    "            style_and_write(frame_count)\n",
    "\n",
    "        video_writer.close()\n",
    "\n",
    "\n",
    "# get img_shape\n",
    "def ffwd(data_in, paths_out, checkpoint_dir, device_t='/gpu:0', batch_size=4):\n",
    "    assert len(paths_out) > 0\n",
    "    is_paths = type(data_in[0]) == str\n",
    "    if is_paths:\n",
    "        assert len(data_in) == len(paths_out)\n",
    "        img_shape = get_img(data_in[0]).shape\n",
    "    else:\n",
    "        assert data_in.size[0] == len(paths_out)\n",
    "        img_shape = X[0].shape\n",
    "\n",
    "    g = tf.Graph()\n",
    "    batch_size = min(len(paths_out), batch_size)\n",
    "    curr_num = 0\n",
    "    soft_config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    soft_config.gpu_options.allow_growth = True\n",
    "    with g.as_default(), g.device(device_t), \\\n",
    "            tf.Session(config=soft_config) as sess:\n",
    "        batch_shape = (batch_size,) + img_shape\n",
    "        img_placeholder = tf.placeholder(tf.float32, shape=batch_shape,\n",
    "                                         name='img_placeholder')\n",
    "\n",
    "        preds = transform.net(img_placeholder)\n",
    "        saver = tf.train.Saver()\n",
    "        if os.path.isdir(checkpoint_dir):\n",
    "            ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "            if ckpt and ckpt.model_checkpoint_path:\n",
    "                saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "            else:\n",
    "                raise Exception(\"No checkpoint found...\")\n",
    "        else:\n",
    "            saver.restore(sess, checkpoint_dir)\n",
    "\n",
    "        num_iters = int(len(paths_out)/batch_size)\n",
    "        for i in range(num_iters):\n",
    "            pos = i * batch_size\n",
    "            curr_batch_out = paths_out[pos:pos+batch_size]\n",
    "            if is_paths:\n",
    "                curr_batch_in = data_in[pos:pos+batch_size]\n",
    "                X = np.zeros(batch_shape, dtype=np.float32)\n",
    "                for j, path_in in enumerate(curr_batch_in):\n",
    "                    img = get_img(path_in)\n",
    "                    assert img.shape == img_shape, \\\n",
    "                        'Images have different dimensions. ' +  \\\n",
    "                        'Resize images or use --allow-different-dimensions.'\n",
    "                    X[j] = img\n",
    "            else:\n",
    "                X = data_in[pos:pos+batch_size]\n",
    "\n",
    "            _preds = sess.run(preds, feed_dict={img_placeholder:X})\n",
    "            for j, path_out in enumerate(curr_batch_out):\n",
    "                save_img(path_out, _preds[j])\n",
    "                \n",
    "        remaining_in = data_in[num_iters*batch_size:]\n",
    "        remaining_out = paths_out[num_iters*batch_size:]\n",
    "    if len(remaining_in) > 0:\n",
    "        ffwd(remaining_in, remaining_out, checkpoint_dir, \n",
    "            device_t=device_t, batch_size=1)\n",
    "\n",
    "def ffwd_to_img(in_path, out_path, checkpoint_dir, device='/cpu:0'):\n",
    "    paths_in, paths_out = [in_path], [out_path]\n",
    "    ffwd(paths_in, paths_out, checkpoint_dir, batch_size=1, device_t=device)\n",
    "\n",
    "def ffwd_different_dimensions(in_path, out_path, checkpoint_dir, \n",
    "            device_t=DEVICE, batch_size=4):\n",
    "    in_path_of_shape = defaultdict(list)\n",
    "    out_path_of_shape = defaultdict(list)\n",
    "    for i in range(len(in_path)):\n",
    "        in_image = in_path[i]\n",
    "        out_image = out_path[i]\n",
    "        shape = \"%dx%dx%d\" % get_img(in_image).shape\n",
    "        in_path_of_shape[shape].append(in_image)\n",
    "        out_path_of_shape[shape].append(out_image)\n",
    "    for shape in in_path_of_shape:\n",
    "        print('Processing images of shape %s' % shape)\n",
    "        ffwd(in_path_of_shape[shape], out_path_of_shape[shape], \n",
    "            checkpoint_dir, device_t, batch_size)\n",
    "\n",
    "def build_parser():\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument('--checkpoint', type=str,\n",
    "                        dest='checkpoint_dir',\n",
    "                        help='dir or .ckpt file to load checkpoint from',\n",
    "                        metavar='CHECKPOINT', required=True)\n",
    "\n",
    "    parser.add_argument('--in-path', type=str,\n",
    "                        dest='in_path',help='dir or file to transform',\n",
    "                        metavar='IN_PATH', required=True)\n",
    "\n",
    "    help_out = 'destination (dir or file) of transformed file or files'\n",
    "    parser.add_argument('--out-path', type=str,\n",
    "                        dest='out_path', help=help_out, metavar='OUT_PATH',\n",
    "                        required=True)\n",
    "\n",
    "    parser.add_argument('--device', type=str,\n",
    "                        dest='device',help='device to perform compute on',\n",
    "                        metavar='DEVICE', default=DEVICE)\n",
    "\n",
    "    parser.add_argument('--batch-size', type=int,\n",
    "                        dest='batch_size',help='batch size for feedforwarding',\n",
    "                        metavar='BATCH_SIZE', default=BATCH_SIZE)\n",
    "\n",
    "    parser.add_argument('--allow-different-dimensions', action='store_true',\n",
    "                        dest='allow_different_dimensions', \n",
    "                        help='allow different image dimensions')\n",
    "\n",
    "    return parser\n",
    "\n",
    "def check_opts(opts):\n",
    "    exists(opts.checkpoint_dir, 'Checkpoint not found!')\n",
    "    exists(opts.in_path, 'In path not found!')\n",
    "    if os.path.isdir(opts.out_path):\n",
    "        exists(opts.out_path, 'out dir not found!')\n",
    "        assert opts.batch_size > 0\n",
    "\n",
    "def main():\n",
    "    parser = build_parser()\n",
    "    opts = parser.parse_args()\n",
    "    check_opts(opts)\n",
    "\n",
    "    if not os.path.isdir(opts.in_path):\n",
    "        if os.path.exists(opts.out_path) and os.path.isdir(opts.out_path):\n",
    "            out_path = \\\n",
    "                    os.path.join(opts.out_path,os.path.basename(opts.in_path))\n",
    "        else:\n",
    "            out_path = opts.out_path\n",
    "\n",
    "        ffwd_to_img(opts.in_path, out_path, opts.checkpoint_dir,\n",
    "                    device=opts.device)\n",
    "    else:\n",
    "        files = list_files(opts.in_path)\n",
    "        full_in = [os.path.join(opts.in_path,x) for x in files]\n",
    "        full_out = [os.path.join(opts.out_path,x) for x in files]\n",
    "        if opts.allow_different_dimensions:\n",
    "            ffwd_different_dimensions(full_in, full_out, opts.checkpoint_dir, \n",
    "                    device_t=opts.device, batch_size=opts.batch_size)\n",
    "        else :\n",
    "            ffwd(full_in, full_out, opts.checkpoint_dir, device_t=opts.device,\n",
    "                    batch_size=opts.batch_size)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from E:\\Documents\\Data_Science\\Analytics_vidya\\FaStyle_Transfer\\fast-style-transfer-master\\data\\wave.ckpt\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[1,32,1536,2048] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node Conv2D (defined at C:\\Users\\indrajit\\Style_Transfer\\transform.py:23)  = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, Variable/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node add_37/_99}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_511_add_37\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'Conv2D', defined at:\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\asyncio\\base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\asyncio\\base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\tornado\\gen.py\", line 1233, in inner\n    self.run()\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3191, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-19e9ba9d2d09>\", line 1, in <module>\n    get_ipython().run_line_magic('run', '-i  evaluate.py --checkpoint E:\\\\Documents\\\\Data_Science\\\\Analytics_vidya\\\\FaStyle_Transfer\\\\fast-style-transfer-master\\\\data\\\\wave.ckpt --in-path E:\\\\Documents\\\\Data_Science\\\\Analytics_vidya\\\\FaStyle_Transfer\\\\fast-style-transfer-master\\\\examples\\\\content\\\\nature.jpg   --out-path E:\\\\Documents\\\\Data_Science\\\\Analytics_vidya\\\\FaStyle_Transfer\\\\fast-style-transfer-master\\\\examples\\\\results  --batch-size 20 --allow-different-dimensions ')\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2287, in run_line_magic\n    result = fn(*args,**kwargs)\n  File \"<decorator-gen-61>\", line 2, in run\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\IPython\\core\\magic.py\", line 187, in <lambda>\n    call = lambda f, *a, **k: f(*a, **k)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\IPython\\core\\magics\\execution.py\", line 807, in run\n    run()\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\IPython\\core\\magics\\execution.py\", line 793, in run\n    exit_ignore=exit_ignore)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2683, in safe_execfile\n    self.compile if shell_futures else None)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\IPython\\utils\\py3compat.py\", line 188, in execfile\n    exec(compiler(f.read(), fname, 'exec'), glob, loc)\n  File \"C:\\Users\\indrajit\\Style_Transfer\\evaluate.py\", line 212, in <module>\n    main()\n  File \"C:\\Users\\indrajit\\Style_Transfer\\evaluate.py\", line 199, in main\n    device=opts.device)\n  File \"C:\\Users\\indrajit\\Style_Transfer\\evaluate.py\", line 132, in ffwd_to_img\n    ffwd(paths_in, paths_out, checkpoint_dir, batch_size=1, device_t=device)\n  File \"C:\\Users\\indrajit\\Style_Transfer\\evaluate.py\", line 93, in ffwd\n    preds = transform.net(img_placeholder)\n  File \"C:\\Users\\indrajit\\Style_Transfer\\transform.py\", line 6, in net\n    conv1 = _conv_layer(image, 32, 9, 1)\n  File \"C:\\Users\\indrajit\\Style_Transfer\\transform.py\", line 23, in _conv_layer\n    net = tf.nn.conv2d(net, weights_init, strides_shape, padding='SAME')\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 957, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[1,32,1536,2048] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node Conv2D (defined at C:\\Users\\indrajit\\Style_Transfer\\transform.py:23)  = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, Variable/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node add_37/_99}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_511_add_37\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1,32,1536,2048] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, Variable/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node add_37/_99}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_511_add_37\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\Style_Transfer\\evaluate.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Style_Transfer\\evaluate.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         ffwd_to_img(opts.in_path, out_path, opts.checkpoint_dir,\n\u001b[1;32m--> 199\u001b[1;33m                     device=opts.device)\n\u001b[0m\u001b[0;32m    200\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[0mfiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Style_Transfer\\evaluate.py\u001b[0m in \u001b[0;36mffwd_to_img\u001b[1;34m(in_path, out_path, checkpoint_dir, device)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mffwd_to_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'/cpu:0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[0mpaths_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpaths_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0min_path\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mout_path\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m     \u001b[0mffwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpaths_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpaths_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice_t\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m def ffwd_different_dimensions(in_path, out_path, checkpoint_dir, \n",
      "\u001b[1;32m~\\Style_Transfer\\evaluate.py\u001b[0m in \u001b[0;36mffwd\u001b[1;34m(data_in, paths_out, checkpoint_dir, device_t, batch_size)\u001b[0m\n\u001b[0;32m    118\u001b[0m                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_in\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m             \u001b[0m_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mimg_placeholder\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath_out\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurr_batch_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m                 \u001b[0msave_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_preds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1,32,1536,2048] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node Conv2D (defined at C:\\Users\\indrajit\\Style_Transfer\\transform.py:23)  = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, Variable/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node add_37/_99}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_511_add_37\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'Conv2D', defined at:\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\asyncio\\base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\asyncio\\base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\tornado\\gen.py\", line 1233, in inner\n    self.run()\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3191, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-19e9ba9d2d09>\", line 1, in <module>\n    get_ipython().run_line_magic('run', '-i  evaluate.py --checkpoint E:\\\\Documents\\\\Data_Science\\\\Analytics_vidya\\\\FaStyle_Transfer\\\\fast-style-transfer-master\\\\data\\\\wave.ckpt --in-path E:\\\\Documents\\\\Data_Science\\\\Analytics_vidya\\\\FaStyle_Transfer\\\\fast-style-transfer-master\\\\examples\\\\content\\\\nature.jpg   --out-path E:\\\\Documents\\\\Data_Science\\\\Analytics_vidya\\\\FaStyle_Transfer\\\\fast-style-transfer-master\\\\examples\\\\results  --batch-size 20 --allow-different-dimensions ')\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2287, in run_line_magic\n    result = fn(*args,**kwargs)\n  File \"<decorator-gen-61>\", line 2, in run\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\IPython\\core\\magic.py\", line 187, in <lambda>\n    call = lambda f, *a, **k: f(*a, **k)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\IPython\\core\\magics\\execution.py\", line 807, in run\n    run()\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\IPython\\core\\magics\\execution.py\", line 793, in run\n    exit_ignore=exit_ignore)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2683, in safe_execfile\n    self.compile if shell_futures else None)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\IPython\\utils\\py3compat.py\", line 188, in execfile\n    exec(compiler(f.read(), fname, 'exec'), glob, loc)\n  File \"C:\\Users\\indrajit\\Style_Transfer\\evaluate.py\", line 212, in <module>\n    main()\n  File \"C:\\Users\\indrajit\\Style_Transfer\\evaluate.py\", line 199, in main\n    device=opts.device)\n  File \"C:\\Users\\indrajit\\Style_Transfer\\evaluate.py\", line 132, in ffwd_to_img\n    ffwd(paths_in, paths_out, checkpoint_dir, batch_size=1, device_t=device)\n  File \"C:\\Users\\indrajit\\Style_Transfer\\evaluate.py\", line 93, in ffwd\n    preds = transform.net(img_placeholder)\n  File \"C:\\Users\\indrajit\\Style_Transfer\\transform.py\", line 6, in net\n    conv1 = _conv_layer(image, 32, 9, 1)\n  File \"C:\\Users\\indrajit\\Style_Transfer\\transform.py\", line 23, in _conv_layer\n    net = tf.nn.conv2d(net, weights_init, strides_shape, padding='SAME')\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 957, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\indrajit\\AppData\\Local\\conda\\conda\\envs\\Kaggle_Compitition\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[1,32,1536,2048] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node Conv2D (defined at C:\\Users\\indrajit\\Style_Transfer\\transform.py:23)  = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, Variable/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node add_37/_99}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_511_add_37\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "%run -i  evaluate.py --checkpoint E:\\Documents\\Data_Science\\Analytics_vidya\\FaStyle_Transfer\\fast-style-transfer-master\\data\\wave.ckpt --in-path E:\\Documents\\Data_Science\\Analytics_vidya\\FaStyle_Transfer\\fast-style-transfer-master\\examples\\content\\nature.jpg   --out-path E:\\Documents\\Data_Science\\Analytics_vidya\\FaStyle_Transfer\\fast-style-transfer-master\\examples\\results  --batch-size 20 --allow-different-dimensions \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: style.py [-h] --checkpoint-dir CHECKPOINT_DIR --style STYLE\n",
      "                [--train-path TRAIN_PATH] [--test TEST] [--test-dir TEST_DIR]\n",
      "                [--slow] [--epochs EPOCHS] [--batch-size BATCH_SIZE]\n",
      "                [--checkpoint-iterations CHECKPOINT_ITERATIONS]\n",
      "                [--vgg-path VGG_PATH] [--content-weight CONTENT_WEIGHT]\n",
      "                [--style-weight STYLE_WEIGHT] [--tv-weight TV_WEIGHT]\n",
      "                [--learning-rate LEARNING_RATE]\n",
      "style.py: error: the following arguments are required: --checkpoint-dir, --style\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "%run -i  style.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load transform_video.py\n",
    "from __future__ import print_function\n",
    "from argparse import ArgumentParser\n",
    "import sys\n",
    "sys.path.insert(0, 'src')\n",
    "import os, random, subprocess, evaluate, shutil\n",
    "from utils import exists, list_files\n",
    "import pdb\n",
    "\n",
    "TMP_DIR = '.fns_frames_%s/' % random.randint(0,99999)\n",
    "DEVICE = '/gpu:0'\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "def build_parser():\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument('--checkpoint', type=str,\n",
    "                        dest='checkpoint', help='checkpoint directory or .ckpt file',\n",
    "                        metavar='CHECKPOINT', required=True)\n",
    "\n",
    "    parser.add_argument('--in-path', type=str,\n",
    "                        dest='in_path', help='in video path',\n",
    "                        metavar='IN_PATH', required=True)\n",
    "    \n",
    "    parser.add_argument('--out-path', type=str,\n",
    "                        dest='out', help='path to save processed video to',\n",
    "                        metavar='OUT', required=True)\n",
    "    \n",
    "    parser.add_argument('--tmp-dir', type=str, dest='tmp_dir',\n",
    "                        help='tmp dir for processing', metavar='TMP_DIR',\n",
    "                        default=TMP_DIR)\n",
    "\n",
    "    parser.add_argument('--device', type=str, dest='device',\n",
    "                        help='device for eval. CPU discouraged. ex: \\'/gpu:0\\'',\n",
    "                        metavar='DEVICE', default=DEVICE)\n",
    "\n",
    "    parser.add_argument('--batch-size', type=int,\n",
    "                        dest='batch_size',help='batch size for eval. default 4.',\n",
    "                        metavar='BATCH_SIZE', default=BATCH_SIZE)\n",
    "\n",
    "    parser.add_argument('--no-disk', type=bool, dest='no_disk',\n",
    "                        help='Don\\'t save intermediate files to disk. Default False',\n",
    "                        metavar='NO_DISK', default=False)\n",
    "    return parser\n",
    "\n",
    "def check_opts(opts):\n",
    "    exists(opts.checkpoint)\n",
    "    exists(opts.out)\n",
    "\n",
    "def main():\n",
    "    parser = build_parser()\n",
    "    opts = parser.parse_args()\n",
    "    evaluate.ffwd_video(opts.in_path, opts.out, opts.checkpoint, opts.device, opts.batch_size)\n",
    "\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: transform_video.py [-h] --checkpoint CHECKPOINT --in-path IN_PATH\n",
      "                          --out-path OUT [--tmp-dir TMP_DIR] [--device DEVICE]\n",
      "                          [--batch-size BATCH_SIZE] [--no-disk NO_DISK]\n",
      "transform_video.py: error: unrecognized arguments: --allow-different-dimensions\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "%run -i transform_video.py --checkpoint E:\\Documents\\Data_Science\\Analytics_vidya\\FaStyle_Transfer\\fast-style-transfer-master\\data\\wave.ckpt --in-path E:\\Documents\\Data_Science\\Analytics_vidya\\FaStyle_Transfer\\fast-style-transfer-master\\examples\\content\\fox.mp4   --out-path E:\\Documents\\Data_Science\\Analytics_vidya\\FaStyle_Transfer\\fast-style-transfer-master\\examples\\results  --batch-size 20 --allow-different-dimensions \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
